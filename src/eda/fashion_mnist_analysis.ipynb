{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Dataset Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook performs an initial exploratory data analysis on the **Fashion-MNIST** dataset, which is a drop-in replacement for the original MNIST dataset. It consists of 70,000 grayscale images (28x28 pixels) of 10 categories of clothing articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 18:15:35.707449: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-30 18:15:35.742599: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-30 18:15:37.276326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-30 18:15:45.059928: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-30 18:15:45.065910: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_fashion_mnist():\n",
    "    # Load train and test data and combine them for full EDA\n",
    "    (X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    X = np.vstack([X_train_full, X_test])\n",
    "    y = np.hstack([y_train_full, y_test])\n",
    "    return X, y\n",
    "\n",
    "X, y = load_fashion_mnist()\n",
    "\n",
    "print(\"=== FASHION-MNIST DATASET EXPLORATORY ANALYSIS ===\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Image dimensions: {X[0].shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "\n",
    "# Class names mapping\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(\"\\n=== CLASS NAMES ===\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"Class {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "# Flatten the images to compute statistics on pixel features\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "df = pd.DataFrame(X_flat)\n",
    "print(f\"Pixel value range: [{X.min()}, {X.max()}]\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(f\"Missing values in features: {np.isnan(X).sum()}\")\n",
    "print(f\"Missing values in target: {np.isnan(y).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Distribution (Class Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print(\"\\n=== TARGET DISTRIBUTION ===\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=range(10), labels=range(10))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "class_counts = pd.Series(y).value_counts().sort_index()\n",
    "plt.pie(class_counts, labels=[class_names[i] for i in class_counts.index], \n",
    "        autopct='%1.1f%%')\n",
    "plt.title('Class Proportions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images\n",
    "print(\"\\n=== SAMPLE IMAGES ===\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(X[i], cmap='gray')\n",
    "    plt.title(f'{class_names[y[i]]} ({y[i]})')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pixel Intensity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel intensity distribution\n",
    "print(\"\\n=== PIXEL INTENSITY DISTRIBUTION ===\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(X_flat.flatten(), bins=50, alpha=0.7)\n",
    "plt.title('Overall Pixel Intensity Distribution')\n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Mean intensity per class\n",
    "mean_intensities = [X_flat[y == i].mean() for i in range(10)]\n",
    "plt.bar(range(10), mean_intensities)\n",
    "plt.title('Mean Pixel Intensity by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Mean Intensity')\n",
    "plt.xticks(range(10), [class_names[i] for i in range(10)], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Class-wise Samples Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-wise samples\n",
    "print(\"\\n=== CLASS-WISE SAMPLE IMAGES ===\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for class_id in range(10):\n",
    "    # Get up to 5 samples for the current class\n",
    "    class_samples = X[y == class_id][:5]\n",
    "    for i, sample in enumerate(class_samples):\n",
    "        # The subplot calculation ensures 5 images per row, 10 rows total\n",
    "        plt.subplot(10, 5, class_id * 5 + i + 1)\n",
    "        plt.imshow(sample, cmap='gray')\n",
    "        if i == 0:\n",
    "            # Label the first image in the row with the class name\n",
    "            plt.ylabel(class_names[class_id], rotation=0, ha='right')\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "print(\"\\n=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"✓ No missing values\")\n",
    "print(f\"✓ Balanced classes\")\n",
    "print(f\"✓ Consistent 28x28 grayscale images\")\n",
    "print(f\"✓ Pixel values in range [0, 255]\")\n",
    "print(f\"✓ Clear visual distinction between classes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
